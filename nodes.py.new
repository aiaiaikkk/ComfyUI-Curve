import torch
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image
import io
from scipy.interpolate import PchipInterpolator, interp1d
import math
import torch.nn.functional as F
import re
from comfy.model_management import get_torch_device

# æ·»åŠ å…¨å±€ç¼“å­˜å­—å…¸ï¼Œç”¨äºå­˜å‚¨æ¯ä¸ªèŠ‚ç‚¹å®ä¾‹çš„ç›´æ–¹å›¾æ•°æ?
_histogram_cache = {}

class PhotoshopCurveNode:
    @classmethod
    def INPUT_TYPES(cls):
        return {
            'required': {
                'image': ('IMAGE',),
                'interpolation': (['linear', 'cubic', 'monotonic'], {'default': 'cubic'}),
                'channel': (['RGB', 'R', 'G', 'B'], {'default': 'RGB'}),
            },
            'optional': {
                'curve_points': ('STRING', {
                    'default': '0,0;255,255', 
                    'multiline': False,
                    'placeholder': 'Format: x1,y1;x2,y2;x3,y3'
                }),
                'curve_strength': ('FLOAT', {
                    'default': 1.0,
                    'min': 0.0,
                    'max': 2.0,
                    'step': 0.1,
                    'display': 'slider'
                }),
                'mask': ('MASK', {
                    'default': None,
                    'tooltip': 'å¯é€‰é®ç½©ï¼Œè°ƒè‰²ä»…å¯¹é®ç½©åŒºåŸŸæœ‰æ•ˆ'
                }),
                'mask_blur': ('FLOAT', {
                    'default': 0.0,
                    'min': 0.0,
                    'max': 20.0,
                    'step': 0.1,
                    'display': 'slider',
                    'tooltip': 'é®ç½©è¾¹ç¼˜ç¾½åŒ–ç¨‹åº¦'
                }),
                'invert_mask': ('BOOLEAN', {
                    'default': False,
                    'tooltip': 'åè½¬é®ç½©åŒºåŸŸ'
                }),
                'show_histogram': ('BOOLEAN', {
                    'default': True,  # é»˜è®¤æ”¹ä¸ºTrueï¼Œè‡ªåŠ¨æ˜¾ç¤ºç›´æ–¹å›¾
                    'tooltip': 'åœ¨æ›²çº¿å›¾èƒŒæ™¯æ˜¾ç¤ºç›´æ–¹å›¾ï¼ˆç±»ä¼¼PSï¼?
                }),
                'histogram_channel': (['Auto', 'RGB', 'R', 'G', 'B', 'Luminance'], {
                    'default': 'Auto',
                    'tooltip': 'ç›´æ–¹å›¾æ˜¾ç¤ºé€šé“ï¼ŒAutoä¼šæ ¹æ®curve channelè‡ªåŠ¨é€‰æ‹©'
                }),
            },
            'hidden': {'unique_id': 'UNIQUE_ID'}
        }
    
    RETURN_TYPES = ('IMAGE', 'IMAGE')
    RETURN_NAMES = ('image', 'curve_chart')
    FUNCTION = 'apply_curve'
    CATEGORY = 'Image/Adjustments'
    OUTPUT_NODE = False
    
    @classmethod
    def IS_CHANGED(cls, image, interpolation, channel, curve_points='0,0;128,128;255,255', curve_strength=1.0, mask=None, mask_blur=0.0, invert_mask=False, show_histogram=True, histogram_channel='Auto', unique_id=None):
        mask_hash = "none" if mask is None else str(hash(mask.data.tobytes()) if hasattr(mask, 'data') else hash(str(mask)))
        return f"{curve_points}_{interpolation}_{channel}_{curve_strength}_{mask_hash}_{mask_blur}_{invert_mask}_{show_histogram}_{histogram_channel}"

    def apply_curve(self, image, interpolation, channel, curve_points='0,0;255,255', curve_strength=1.0, mask=None, mask_blur=0.0, invert_mask=False, show_histogram=True, histogram_channel='Auto', unique_id=None):
        try:
            # ç¡®ä¿è¾“å…¥å›¾åƒæ ¼å¼æ­£ç¡®
            if image is None:
                raise ValueError("Input image is None")
            
            # å¤„ç†æ‰¹æ¬¡ç»´åº¦
            if image.dim() == 4:  # Batch dimension exists
                batch_size = image.shape[0]
                results = []
                curve_charts = []
                
                for b in range(batch_size):
                    # å¤„ç†å¯¹åº”çš„é®ç½?
                    batch_mask = None
                    if mask is not None:
                        if mask.dim() == 3 and mask.shape[0] > b:
                            batch_mask = mask[b]
                        elif mask.dim() == 2:
                            batch_mask = mask
                        elif mask.dim() == 3 and mask.shape[0] == 1:
                            batch_mask = mask[0]
                    
                    result, curve_chart = self._process_single_image(
                        image[b], curve_points, interpolation, channel, curve_strength, 
                        batch_mask, mask_blur, invert_mask, show_histogram, histogram_channel
                    )
                    results.append(result)
                    curve_charts.append(curve_chart)
                return (torch.stack(results, dim=0), torch.stack(curve_charts, dim=0))
            else:
                result, curve_chart = self._process_single_image(
                    image, curve_points, interpolation, channel, curve_strength,
                    mask, mask_blur, invert_mask, show_histogram, histogram_channel
                )
                return (result.unsqueeze(0), curve_chart.unsqueeze(0))  # æ·»åŠ æ‰¹æ¬¡ç»´åº¦
                
        except Exception as e:
            print(f"PhotoshopCurveNode error: {e}")
            # è¿”å›åŸå§‹å›¾åƒä½œä¸ºfallback
            return (image, self._create_fallback_curve_chart().unsqueeze(0))
    
    def _process_single_image(self, image, curve_points, interpolation, channel, curve_strength, mask=None, mask_blur=0.0, invert_mask=False, show_histogram=True, histogram_channel='Auto'):
        # ç¡®ä¿å›¾åƒåœ¨æ­£ç¡®çš„è®¾å¤‡ä¸?
        device = get_torch_device()
        image = image.to(device)
        
        # å¤„ç†å›¾åƒç»´åº¦ (HWC)
        if image.dim() == 3:
            h, w, c = image.shape
        else:
            raise ValueError(f"Unexpected image dimensions: {image.shape}")
        
        # è§£ææ§åˆ¶ç‚?
        control_points = self._parse_control_points(curve_points)
        if len(control_points) < 2:
            print("Warning: Less than 2 control points, using default curve")
            control_points = [(0, 0), (255, 255)]
        
        # æ„å»ºæŸ¥æ‰¾è¡?
        lut = self._build_lookup_table(control_points, interpolation)
        
        # åº”ç”¨æ›²çº¿å¼ºåº¦
        if curve_strength != 1.0:
            # åœ¨åŸå§‹å€¼å’Œæ›²çº¿å€¼ä¹‹é—´æ’å€?
            identity_lut = np.arange(256, dtype=np.float32)
            lut = identity_lut * (1 - curve_strength) + lut * curve_strength
        
        # åº”ç”¨LUTåˆ°å›¾åƒ?
        result = self._apply_lut_to_image(image, lut, channel)
        
        # å¤„ç†é®ç½©
        if mask is not None:
            result = self._apply_mask(image, result, mask, mask_blur, invert_mask)
        
        # ç”Ÿæˆæ›²çº¿å›¾åƒ - ä½¿ç”¨å¤„ç†åçš„å›¾åƒ
        curve_chart = self._generate_curve_chart(result, show_histogram, histogram_channel, control_points, interpolation, curve_strength)
        
        return result, curve_chart
    
    def _parse_control_points(self, curve_points_str):
        """è§£ææ§åˆ¶ç‚¹å­—ç¬¦ä¸²"""
        points = []
        try:
            segments = curve_points_str.strip().split(';')
            for segment in segments:
                if not segment.strip():
                    continue
                parts = segment.strip().split(',')
                if len(parts) == 2:
                    x = float(parts[0])
                    y = float(parts[1])
                    # é™åˆ¶åœ¨æœ‰æ•ˆèŒƒå›´å†…
                    x = max(0, min(255, x))
                    y = max(0, min(255, y))
                    points.append((x, y))
        except Exception as e:
            print(f"Error parsing control points: {e}")
            return [(0, 0), (255, 255)]
        
        # æŒ‰xåæ ‡æ’åº
        points.sort(key=lambda p: p[0])
        
        # ç¡®ä¿æœ‰èµ·å§‹å’Œç»“æŸç‚?
        if not points or points[0][0] > 0:
            points.insert(0, (0, 0))
        if not points or points[-1][0] < 255:
            points.append((255, 255))
        
        return points
    
    def _build_lookup_table(self, control_points, interpolation):
        """æ„å»ºæŸ¥æ‰¾è¡?""
        xs = [p[0] for p in control_points]
        ys = [p[1] for p in control_points]
        
        # åˆ›å»º0-255çš„è¾“å…¥æ•°ç»?
        input_range = np.arange(256, dtype=np.float32)
        
        try:
            if interpolation == 'linear':
                lut = np.interp(input_range, xs, ys)
            elif interpolation == 'cubic':
                if len(xs) >= 2:
                    spline = CubicSpline(xs, ys, bc_type='natural')
                    lut = spline(input_range)
                else:
                    lut = np.interp(input_range, xs, ys)
            elif interpolation == 'monotonic':
                if len(xs) >= 2:
                    # ä½¿ç”¨å•è°ƒä¸‰æ¬¡æ ·æ¡
                    spline = CubicSpline(xs, ys, bc_type='clamped')
                    lut = spline(input_range)
                    # ç¡®ä¿å•è°ƒæ€§ï¼ˆå¦‚æœéœ€è¦ï¼‰
                    lut = np.maximum.accumulate(lut)
                else:
                    lut = np.interp(input_range, xs, ys)
            else:
                lut = np.interp(input_range, xs, ys)
                
        except Exception as e:
            print(f"Error building LUT: {e}, falling back to linear interpolation")
            lut = np.interp(input_range, xs, ys)
        
        # ç¡®ä¿LUTåœ¨æœ‰æ•ˆèŒƒå›´å†…
        lut = np.clip(lut, 0, 255).astype(np.float32)
        return lut
    
    def _apply_lut_to_image(self, image, lut, channel):
        """å°†LUTåº”ç”¨åˆ°å›¾åƒ?""
        device = image.device
        
        # å°†å›¾åƒå€¼ç¼©æ”¾åˆ°0-255èŒƒå›´è¿›è¡ŒLUTæŸ¥æ‰¾
        img_255 = (image * 255.0).clamp(0, 255)
        
        # åˆ›å»ºè¾“å‡ºå›¾åƒ
        output = torch.zeros_like(img_255)
        
        # è½¬æ¢LUTä¸ºtensor
        lut_tensor = torch.tensor(lut, device=device, dtype=torch.float32)
        
        # æ ¹æ®é€šé“è®¾ç½®åº”ç”¨LUT
        num_channels = img_255.shape[-1]
        
        for c in range(num_channels):
            channel_name = ['R', 'G', 'B'][c] if num_channels == 3 else str(c)
            
            if channel == 'RGB' or channel_name == channel:
                # è·å–å½“å‰é€šé“çš„åƒç´ å€?
                channel_data = img_255[..., c]
                
                # å°†åƒç´ å€¼è½¬æ¢ä¸ºæ•´æ•°ç´¢å¼•
                indices = channel_data.long().clamp(0, 255)
                
                # ä½¿ç”¨LUTè¿›è¡Œæ˜ å°„
                output[..., c] = lut_tensor[indices]
            else:
                # ä¸å¤„ç†çš„é€šé“ä¿æŒåŸå€?
                output[..., c] = img_255[..., c]
        
        # å°†ç»“æœç¼©æ”¾å›0-1èŒƒå›´
        result = (output / 255.0).clamp(0, 1)
        
        return result

    def _apply_mask(self, original_image, processed_image, mask, mask_blur, invert_mask):
        """åº”ç”¨é®ç½©ï¼Œæ··åˆåŸå›¾å’Œå¤„ç†åçš„å›¾åƒ"""
        device = original_image.device
        h, w = original_image.shape[:2]
        
        # å¤„ç†é®ç½©
        if mask is None:
            return processed_image
        
        # ç¡®ä¿é®ç½©åœ¨æ­£ç¡®çš„è®¾å¤‡ä¸?
        mask = mask.to(device)
        
        # å¤„ç†é®ç½©ç»´åº¦ï¼Œç¡®ä¿ä¸å›¾åƒåŒ¹é…
        if mask.dim() == 2:
            # é®ç½©æ˜?(H, W)
            if mask.shape[0] != h or mask.shape[1] != w:
                # è°ƒæ•´é®ç½©å°ºå¯¸ä»¥åŒ¹é…å›¾åƒ?
                mask = torch.nn.functional.interpolate(
                    mask.unsqueeze(0).unsqueeze(0), 
                    size=(h, w), 
                    mode='bilinear', 
                    align_corners=False
                ).squeeze(0).squeeze(0)
        elif mask.dim() == 3:
            # é®ç½©æ˜?(1, H, W) æˆ?(H, W, 1)
            if mask.shape[0] == 1:
                mask = mask.squeeze(0)
            elif mask.shape[2] == 1:
                mask = mask.squeeze(2)
            
            # å†æ¬¡æ£€æŸ¥å°ºå¯?
            if mask.shape[0] != h or mask.shape[1] != w:
                mask = torch.nn.functional.interpolate(
                    mask.unsqueeze(0).unsqueeze(0), 
                    size=(h, w), 
                    mode='bilinear', 
                    align_corners=False
                ).squeeze(0).squeeze(0)
        
        # ç¡®ä¿é®ç½©å€¼åœ¨ [0, 1] èŒƒå›´å†?
        mask = torch.clamp(mask, 0.0, 1.0)
        
        # åè½¬é®ç½©ï¼ˆå¦‚æœéœ€è¦ï¼‰
        if invert_mask:
            mask = 1.0 - mask
        
        # åº”ç”¨é«˜æ–¯æ¨¡ç³Šç¾½åŒ–æ•ˆæœ
        if mask_blur > 0.0:
            mask = self._apply_gaussian_blur(mask, mask_blur)
        
        # æ‰©å±•é®ç½©ç»´åº¦ä»¥åŒ¹é…å›¾åƒé€šé“ (H, W) -> (H, W, C)
        if original_image.dim() == 3:
            mask = mask.unsqueeze(-1).expand(-1, -1, original_image.shape[2])
        
        # æ··åˆåŸå›¾å’Œå¤„ç†åçš„å›¾åƒ?
        # result = original * (1 - mask) + processed * mask
        result = original_image * (1.0 - mask) + processed_image * mask
        
        return result
    
    def _apply_gaussian_blur(self, tensor, blur_radius):
        """å¯¹tensoråº”ç”¨é«˜æ–¯æ¨¡ç³Š"""
        if blur_radius <= 0:
            return tensor
        
        device = tensor.device
        
        # è®¡ç®—é«˜æ–¯æ ¸å¤§å°ï¼ˆå¥‡æ•°ï¼?
        kernel_size = int(blur_radius * 2) * 2 + 1
        sigma = blur_radius / 3.0
        
        # åˆ›å»º1Dé«˜æ–¯æ ?
        x = torch.arange(kernel_size, dtype=torch.float32, device=device) - kernel_size // 2
        gauss_1d = torch.exp(-0.5 * (x / sigma) ** 2)
        gauss_1d = gauss_1d / gauss_1d.sum()
        
        # åˆ›å»º2Dé«˜æ–¯æ ?
        gauss_2d = gauss_1d.unsqueeze(0) * gauss_1d.unsqueeze(1)
        gauss_2d = gauss_2d.unsqueeze(0).unsqueeze(0)  # (1, 1, kernel_size, kernel_size)
        
        # æ·»åŠ paddingä»¥ä¿æŒå°ºå¯?
        padding = kernel_size // 2
        
        # åº”ç”¨å·ç§¯
        blurred = torch.nn.functional.conv2d(
            tensor.unsqueeze(0).unsqueeze(0),  # (1, 1, H, W)
            gauss_2d,
            padding=padding
        ).squeeze(0).squeeze(0)  # (H, W)
        
        return blurred

    def _generate_curve_chart(self, image, show_histogram, histogram_channel, control_points=None, interpolation='cubic', curve_strength=1.0):
        """ç”Ÿæˆæ›²çº¿å›¾åƒ - ç»Ÿä¸€é£æ ¼çš„ç‰ˆæœ?""
        try:
            # åˆ›å»ºå›¾è¡¨
            fig, ax = plt.subplots(figsize=(4, 4), dpi=100)
            
            # è®¾ç½®èƒŒæ™¯å’Œç½‘æ ¼é£æ ¼ï¼ˆä¸æ›²çº¿ç¼–è¾‘å™¨ä¸€è‡´ï¼‰
            fig.patch.set_facecolor('#2a2a2a')  # å¤–éƒ¨èƒŒæ™¯
            ax.set_facecolor('#1a1a1a')  # å†…éƒ¨èƒŒæ™¯
            
            # è®¾ç½®å›¾è¡¨èŒƒå›´
            ax.set_xlim(0, 255)
            ax.set_ylim(0, 255)
            
            # ç»˜åˆ¶ç½‘æ ¼ï¼ˆä¸æ›²çº¿ç¼–è¾‘å™¨ä¸€è‡´ï¼‰
            gridColor = '#444444'
            ax.grid(True, color=gridColor, alpha=0.5, linestyle='-', linewidth=0.5)
            
            # è®¾ç½®è½´æ ‡ç­¾é¢œè‰?
            ax.tick_params(axis='x', colors='white', labelsize=8)
            ax.tick_params(axis='y', colors='white', labelsize=8)
            ax.spines['bottom'].set_color('#555')
            ax.spines['top'].set_color('#555')
            ax.spines['left'].set_color('#555')
            ax.spines['right'].set_color('#555')
            
            # æ·»åŠ è‰²è°ƒæ ‡ç­¾ï¼ˆæ¨¡ä»¿æ›²çº¿ç¼–è¾‘å™¨çš„æ ‡ç­¾ï¼‰
            tone_points = [
                (0, 0, "ç™½è‰²"), 
                (64, 64, "é«˜å…‰"), 
                (128, 128, "ä¸­é—´è°?), 
                (192, 192, "é˜´å½±"), 
                (255, 255, "é»‘è‰²")
            ]
            
            for x, y, label in tone_points:
                ax.text(x, 255-y, label, color='#888', fontsize=8, 
                       ha='center', va='center', alpha=0.7)
            
            # å¦‚æœå¯ç”¨äº†ç›´æ–¹å›¾æ˜¾ç¤ºï¼Œç›´æ¥ä»å½“å‰å›¾åƒç”Ÿæˆç›´æ–¹å›?
            if show_histogram:
                self._draw_histogram_background(ax, image, histogram_channel)
            
            # ç»˜åˆ¶å¯¹è§’çº¿ï¼ˆçº¿æ€§æ›²çº¿å‚è€ƒï¼‰
            ax.plot([0, 255], [0, 255], color='#555555', linestyle='--', alpha=0.5, linewidth=1)
            
            # ç»˜åˆ¶æ›²çº¿
            if control_points and len(control_points) >= 2:
                try:
                    # æå–xå’Œyåæ ‡
                    x_points = [p[0] for p in control_points]
                    y_points = [p[1] for p in control_points]
                    
                    # ç»˜åˆ¶æ§åˆ¶ç‚?
                    ax.scatter(x_points, y_points, color='#4ecdc4', s=30, zorder=3)
                    
                    # æ„å»ºæŸ¥æ‰¾è¡¨è·å–å®Œæ•´æ›²çº?
                    lut = self._build_lookup_table(control_points, interpolation)
                    
                    # åº”ç”¨æ›²çº¿å¼ºåº¦ï¼ˆå¦‚æœéœ€è¦ï¼‰
                    if curve_strength != 1.0:
                        identity_lut = np.arange(256, dtype=np.float32)
                        lut = identity_lut * (1 - curve_strength) + lut * curve_strength
                    
                    # ç»˜åˆ¶æ›²çº¿
                    ax.plot(np.arange(256), lut, color='#4ecdc4', linewidth=2, zorder=2)
                except Exception as curve_error:
                    print(f"Error drawing curve on chart: {curve_error}")
            
            # ä¿å­˜å›¾è¡¨ä¸ºå›¾åƒ?
            buf = io.BytesIO()
            fig.savefig(buf, format='png', bbox_inches='tight', pad_inches=0.1, facecolor='#2a2a2a')
            plt.close(fig)
            
            # è½¬æ¢ä¸ºPILå›¾åƒ
            buf.seek(0)
            chart_pil = Image.open(buf)
            
            # è°ƒæ•´å›¾åƒå¤§å°
            chart_pil = chart_pil.resize((512, 512), Image.LANCZOS)
            
            # è½¬æ¢ä¸ºRGBæ¨¡å¼
            if chart_pil.mode != 'RGB':
                chart_pil = chart_pil.convert('RGB')
            
            # è½¬æ¢ä¸ºtensor
            chart_np = np.array(chart_pil) / 255.0
            chart_tensor = torch.from_numpy(chart_np).float().to(get_torch_device())
            
            return chart_tensor
        
        except Exception as e:
            print(f"Error generating curve chart: {e}")
            return self._create_fallback_curve_chart()
    
    def _draw_histogram_background(self, ax, image, histogram_channel):
        """åœ¨æ›²çº¿å›¾èƒŒæ™¯ç»˜åˆ¶ç›´æ–¹å›?- ç»Ÿä¸€é£æ ¼çš„ç‰ˆæœ?""
        try:
            # å°†å›¾åƒè½¬æ¢ä¸º0-255èŒƒå›´
            img_255 = (image * 255.0).clamp(0, 255)
            
            # ç¡®å®šè¦æ˜¾ç¤ºçš„é€šé“
            if histogram_channel == 'Auto':
                # æ ¹æ®å½“å‰å¤„ç†çš„é€šé“è‡ªåŠ¨é€‰æ‹©
                histogram_channel = 'RGB'  # é»˜è®¤æ˜¾ç¤ºRGB
            
            if histogram_channel == 'RGB':
                # æ˜¾ç¤ºRGBä¸‰ä¸ªé€šé“çš„ç›´æ–¹å›¾
                colors = ['#ff5555', '#55ff55', '#5555ff']  # æ›´é²œæ˜çš„RGBé¢œè‰²
                alphas = [0.3, 0.3, 0.3]
                
                for c, (color, alpha) in enumerate(zip(colors, alphas)):
                    if c < img_255.shape[2]:
                        channel_data = img_255[..., c].cpu().numpy().flatten()
                        hist, bins = np.histogram(channel_data, bins=256, range=(0, 255))
                        
                        # å½’ä¸€åŒ–ç›´æ–¹å›¾åˆ?-255èŒƒå›´
                        hist_normalized = (hist / np.max(hist)) * 255 if np.max(hist) > 0 else hist
                        hist_normalized = hist_normalized * 0.8  # ç¼©æ”¾åˆ°å›¾è¡¨é«˜åº¦çš„80%
                        
                        # ç»˜åˆ¶ç›´æ–¹å›¾ä½œä¸ºèƒŒæ™?
                        ax.fill_between(bins[:-1], 0, hist_normalized, 
                                      alpha=alpha, color=color, step='pre')
                        
            elif histogram_channel == 'Luminance':
                # æ˜¾ç¤ºäº®åº¦ç›´æ–¹å›?
                if img_255.shape[2] >= 3:
                    luminance = (img_255[..., 0] * 0.299 + 
                               img_255[..., 1] * 0.587 + 
                               img_255[..., 2] * 0.114)
                    lum_data = luminance.cpu().numpy().flatten()
                    hist, bins = np.histogram(lum_data, bins=256, range=(0, 255))
                    
                    # å½’ä¸€åŒ–ç›´æ–¹å›¾
                    hist_normalized = (hist / np.max(hist)) * 255 if np.max(hist) > 0 else hist
                    hist_normalized = hist_normalized * 0.8  # ç¼©æ”¾åˆ°å›¾è¡¨é«˜åº¦çš„80%
                    
                    # ç»˜åˆ¶ç°è‰²ç›´æ–¹å›?
                    ax.fill_between(bins[:-1], 0, hist_normalized, 
                                  alpha=0.3, color='#aaaaaa', step='pre')
                    
            else:
                # å•é€šé“ç›´æ–¹å›?
                channel_idx = {'R': 0, 'G': 1, 'B': 2}.get(histogram_channel, 0)
                colors = {'R': '#ff5555', 'G': '#55ff55', 'B': '#5555ff'}
                color = colors.get(histogram_channel, '#aaaaaa')
                
                if channel_idx < img_255.shape[2]:
                    channel_data = img_255[..., channel_idx].cpu().numpy().flatten()
                    hist, bins = np.histogram(channel_data, bins=256, range=(0, 255))
                    
                    # å½’ä¸€åŒ–ç›´æ–¹å›¾
                    hist_normalized = (hist / np.max(hist)) * 255 if np.max(hist) > 0 else hist
                    hist_normalized = hist_normalized * 0.8  # ç¼©æ”¾åˆ°å›¾è¡¨é«˜åº¦çš„80%
                    
                    # ç»˜åˆ¶å•é€šé“ç›´æ–¹å›?
                    ax.fill_between(bins[:-1], 0, hist_normalized, 
                                  alpha=0.4, color=color, step='pre')
                    
        except Exception as e:
            print(f"Error drawing histogram background: {e}")

    def _create_fallback_curve_chart(self):
        """åˆ›å»ºå¤‡ç”¨æ›²çº¿å›¾åƒ - ç»Ÿä¸€é£æ ¼çš„ç‰ˆæœ?""
        try:
            # åˆ›å»ºä¸€ä¸ªç®€å•çš„é”™è¯¯å›¾åƒ
            fig, ax = plt.subplots(figsize=(5, 5), dpi=100)
            fig.patch.set_facecolor('#2a2a2a')  # å¤–éƒ¨èƒŒæ™¯
            
            ax.set_facecolor('#1a1a1a')  # å†…éƒ¨èƒŒæ™¯
            ax.text(0.5, 0.5, 'Error generating curve chart\nPlease check console for details', 
                   horizontalalignment='center', verticalalignment='center',
                   transform=ax.transAxes, fontsize=12, color='#ff5555')
            ax.set_xlim(0, 255)
            ax.set_ylim(0, 255)
            ax.set_xlabel('Input', color='#cccccc', fontsize=10)
            ax.set_ylabel('Output', color='#cccccc', fontsize=10)
            ax.set_title('Curve Chart Error', color='white', fontsize=12)
            ax.tick_params(colors='#cccccc')
            
            # è®¾ç½®è¾¹æ¡†é¢œè‰²
            for spine in ax.spines.values():
                spine.set_color('#555555')
            
            # ç»˜åˆ¶å¯¹è§’çº¿ï¼ˆçº¿æ€§æ›²çº¿å‚è€ƒï¼‰
            ax.plot([0, 255], [0, 255], color='#555555', linestyle='--', alpha=0.5, linewidth=1)
            
            # ç»˜åˆ¶ç½‘æ ¼çº?
            gridColor = '#444444'
            ax.grid(True, color=gridColor, alpha=0.5, linestyle='-', linewidth=0.5)
            
            # è½¬æ¢ä¸ºtensor
            buf = io.BytesIO()
            plt.savefig(buf, format='png', dpi=100, bbox_inches='tight', pad_inches=0.1, facecolor='#2a2a2a')
            plt.close(fig)
            buf.seek(0)
            
            pil_image = Image.open(buf)
            pil_image = pil_image.resize((512, 512), Image.LANCZOS)
            
            if pil_image.mode != 'RGB':
                pil_image = pil_image.convert('RGB')
            
            img_array = np.array(pil_image)
            curve_chart_tensor = torch.from_numpy(img_array).float() / 255.0
            
            return curve_chart_tensor.to(get_torch_device())
        except Exception as e:
            print(f"Error creating fallback curve chart: {e}")
            # åˆ›å»ºçº¯è‰²å›¾åƒä½œä¸ºæœ€åçš„å¤‡ç”¨
            empty_chart = torch.ones((512, 512, 3), dtype=torch.float32).to(get_torch_device()) * 0.1
            # åœ¨ä¸­é—´ç»˜åˆ¶çº¢è‰²åå­—è¡¨ç¤ºé”™è¯?
            empty_chart[236:276, 236:276, 0] = 1.0
            empty_chart[236:276, 236:276, 1] = 0.0
            empty_chart[236:276, 236:276, 2] = 0.0
            return empty_chart

class CurvePresetNode:
    @classmethod
    def INPUT_TYPES(cls):
        return {
            'required': {
                'preset_style': ([
                    'Linear (æ— è°ƒæ•?',
                    
                    # åŸºç¡€é£æ ¼ï¼ˆæ•ˆæœæ˜æ˜¾ï¼‰
                    'äººåƒä¸“ç”¨', 'é£æ™¯ä¸“ç”¨', 'å¤œæ™¯ä¸“ç”¨',
                    
                    # å¯¹æ¯”åº¦ç³»åˆ—ï¼ˆæ•ˆæœæœ€æ˜æ˜¾ï¼?
                    'é«˜å¯¹æ¯”åº¦', 'è¶…é«˜å¯¹æ¯”', 'æŸ”å’Œå¯¹æ¯”', 'æš—è°ƒé£æ ¼', 'äº®è°ƒé£æ ¼',
                    
                    # ç”µå½±çº§è°ƒè‰²ï¼ˆé£æ ¼åŒ–å¼ºçƒˆï¼‰
                    'ç”µå½±è“æ©™', 'èµ›åšæœ‹å…‹', 'æœ«æ—¥åºŸåœŸ', 'å¤å¤ç”µå½±', 'ç°ä»£ç”µå½±',
                    
                    # èƒ¶ç‰‡é£æ ¼ï¼ˆå¤å¤æ„Ÿå¼ºçƒˆï¼?
                    'VSCOç»å…¸', 'æŸ¯è¾¾èƒ¶ç‰‡', 'å¯Œå£«èƒ¶ç‰‡', 'å®ä¸½æ?, 'é»‘ç™½èƒ¶ç‰‡',
                    
                    # æ—¥ç³»é£æ ¼ï¼ˆæ¸…æ–°æ˜æ˜¾ï¼‰
                    'æ—¥ç³»æ¸…æ–°', 'æ—¥ç³»é€šé€?, 'æ—¥ç³»å¥¶æ²¹', 'æ—¥ç³»æ£®ç³»',
                    
                    # æ¸¯é£ç³»åˆ—ï¼ˆå¤å¤æ¸¯ç‰‡ï¼‰
                    'æ¸¯é£ç»å…¸', 'æ¸¯é£æš—è°ƒ', 'æ¸¯é£éœ“è™¹',
                    
                    # ç¤¾äº¤åª’ä½“é£æ ¼
                    'å°çº¢ä¹?, 'Instagram', 'TikTokæµè¡Œ',
                    
                    # æ—¶å°šæ‘„å½±
                    'æ—¶å°šæ‚å¿—', 'é«˜çº§ç?, 'è«å…°è¿ªè‰²', 'å¥¶èŒ¶è‰?,
                    
                    # è‰ºæœ¯é£æ ¼
                    'æ²¹ç”»è´¨æ„Ÿ', 'æ°´å½©ç”?, 'ç´ æé£æ ¼', 'ç‰ˆç”»æ•ˆæœ',
                    
                    # ç‰¹æ®Šæ•ˆæœï¼ˆæ•ˆæœå¼ºçƒˆï¼‰
                    'æ¢¦å¹»ç´«è°ƒ', 'é’æ˜¥æ´»åŠ›', 'å•†ä¸šæ‘„å½±', 'å©šçº±æ‘„å½±', 'è¡—æ‹é£æ ¼',
                    
                    # å­£èŠ‚ä¸»é¢˜
                    'æ˜¥æ—¥æš–é˜³', 'å¤æ—¥æ¸…å‡‰', 'ç§‹æ—¥é‡‘é»„', 'å†¬æ—¥é›ªæ™¯',
                    
                    # æç«¯æ•ˆæœï¼ˆæµ‹è¯•ç”¨ï¼?
                    'æç«¯æäº®', 'æç«¯å‹æš—', 'åè½¬æ•ˆæœ', 'Så‹å¢å¼?,
                    
                    # === äººåƒæ‘„å½± ===
                    'äººåƒç¾é¢œ', 'äººåƒè´¨æ„Ÿ', 'äººåƒæŸ”å…‰',
                    
                    # === é£æ™¯æ‘„å½± ===
                    'é£æ™¯å¢å¼º', 'è‡ªç„¶é£å…‰', 'å±±æ°´ç”»æ„',
                    
                    # === ç”µå½±é£æ ¼ ===
                    'ç”µå½±èƒ¶ç‰‡', 'ç”µå½±å†·è°ƒ', 'ç”µå½±æš–è°ƒ',
                    
                    # === å¤å¤é£æ ¼ ===
                    'å¤å¤èƒ¶ç‰‡', 'å¤å¤æš–è°ƒ', 'æ€€æ—§è‰²è°?,
                    
                    # === ç°ä»£é£æ ¼ ===
                    'ç°ä»£ç®€çº?, 'ç§‘æŠ€æ„?, 'æœªæ¥ä¸»ä¹‰',
                    
                    # === å¯¹æ¯”åº¦ç³»åˆ?===
                    'é«˜å¯¹æ¯”åº¦', 'è¶…é«˜å¯¹æ¯”', 'æŸ”å’Œå¯¹æ¯”', 'æš—è°ƒé£æ ¼', 'äº®è°ƒé£æ ¼'
                ], {'default': 'Linear (æ— è°ƒæ•?'}),
            },
            'hidden': {'unique_id': 'UNIQUE_ID'}
        }
    
    RETURN_TYPES = ('STRING',)
    RETURN_NAMES = ('curve_points',)
    FUNCTION = 'get_preset_curve'
    CATEGORY = 'Image/Adjustments'
    OUTPUT_NODE = False
    
    @classmethod
    def IS_CHANGED(cls, preset_style, unique_id=None):
        return f"{preset_style}"

    def get_preset_curves(self):
        """å®šä¹‰å„ç§é£æ ¼çš„é¢„è®¾æ›²çº?- ä¼˜åŒ–ç‰ˆæœ¬ï¼Œæ•ˆæœæ›´æ˜æ˜¾"""
        return {
            'Linear (æ— è°ƒæ•?': '0,0;255,255',
            
            # === åŸºç¡€é£æ ¼ï¼ˆæ•ˆæœæ˜æ˜¾ï¼‰ ===
            'äººåƒä¸“ç”¨': '0,15;64,85;128,155;192,210;255,245',  # æäº®è‚¤è‰²ï¼ŒæŸ”åŒ–å¯¹æ¯?
            'é£æ™¯ä¸“ç”¨': '0,0;32,15;96,75;160,185;224,245;255,255',  # å¢å¼ºå¤©ç©ºå’Œæ¤ç‰©å¯¹æ¯?
            'å¤œæ™¯ä¸“ç”¨': '0,25;48,80;96,130;160,190;224,230;255,250',  # å¤§å¹…æäº®æš—éƒ¨ç»†èŠ‚
            
            # === å¯¹æ¯”åº¦ç³»åˆ—ï¼ˆæ•ˆæœæœ€æ˜æ˜¾ï¼?===
            'é«˜å¯¹æ¯”åº¦': '0,0;48,25;128,128;208,230;255,255',  # å¼ºçƒˆSå‹æ›²çº?
            'è¶…é«˜å¯¹æ¯”': '0,0;64,15;128,128;192,240;255,255',  # æç«¯å¯¹æ¯”æ•ˆæœ
            'æŸ”å’Œå¯¹æ¯”': '0,20;64,80;128,140;192,200;255,240',  # æ¸©å’Œæå‡å¯¹æ¯”
            'æš—è°ƒé£æ ¼': '0,0;64,35;128,85;192,140;255,200',  # æ•´ä½“å‹æš—ï¼Œè¥é€ æ°›å›?
            'äº®è°ƒé£æ ¼': '0,50;64,100;128,170;192,220;255,255',  # å¤§å¹…æäº®ï¼Œæ¸…æ–°é£æ ?
            
            # === ç”µå½±çº§è°ƒè‰²ï¼ˆé£æ ¼åŒ–å¼ºçƒˆï¼‰ ===
            'ç”µå½±è“æ©™': '0,10;48,35;96,80;160,180;208,235;255,250',  # ç»å…¸ç”µå½±è‰²è°ƒ
            'èµ›åšæœ‹å…‹': '0,0;32,15;96,60;160,200;224,250;255,255',  # ç§‘å¹»å†·è°ƒ
            'æœ«æ—¥åºŸåœŸ': '0,0;64,40;128,95;192,150;255,210',  # è’å‡‰æš—è°ƒ
            'å¤å¤ç”µå½±': '0,5;48,45;96,90;160,170;224,220;255,245',  # å¤å¤æš–è°ƒ
            'ç°ä»£ç”µå½±': '0,0;64,50;128,120;192,200;255,255',  # ç°ä»£å†·è°ƒ
            
            # === èƒ¶ç‰‡é£æ ¼ï¼ˆå¤å¤æ„Ÿå¼ºçƒˆï¼?===
            'VSCOç»å…¸': '0,20;32,50;96,110;160,180;224,230;255,245',  # ç»å…¸VSCOæ•ˆæœ
            'æŸ¯è¾¾èƒ¶ç‰‡': '0,25;48,70;96,125;160,185;224,230;255,245',  # æš–è°ƒèƒ¶ç‰‡
            'å¯Œå£«èƒ¶ç‰‡': '0,15;64,85;128,150;192,210;255,245',  # æ¸…æ–°èƒ¶ç‰‡
            'å®ä¸½æ?: '0,35;48,85;96,140;160,190;224,225;255,240',  # å¤å¤å³æ—¶æˆåƒ
            'é»‘ç™½èƒ¶ç‰‡': '0,0;48,35;96,80;160,175;224,230;255,255',  # é»‘ç™½èƒ¶ç‰‡è´¨æ„Ÿ
            
            # === æ—¥ç³»é£æ ¼ï¼ˆæ¸…æ–°æ˜æ˜¾ï¼‰ ===
            'æ—¥ç³»æ¸…æ–°': '0,35;64,100;128,170;192,225;255,250',  # æ›´æ˜äº®æ¸…æ–°ï¼Œä¸å†¬æ—¥é›ªæ™¯åŒºåˆ?
            'æ—¥ç³»é€šé€?: '0,40;48,90;96,145;144,190;192,225;255,250',  # é€šé€æ˜äº?
            'æ—¥ç³»å¥¶æ²¹': '0,45;48,100;96,155;144,200;192,235;255,250',  # å¥¶æ²¹è´¨æ„Ÿ
            'æ—¥ç³»æ£®ç³»': '0,20;64,80;128,145;192,200;255,240',  # æ›´è‡ªç„¶ï¼Œä¸æ˜¥æ—¥æš–é˜³åŒºåˆ?
            
            # === æ¸¯é£ç³»åˆ—ï¼ˆå¤å¤æ¸¯ç‰‡ï¼‰ ===
            'æ¸¯é£ç»å…¸': '0,0;48,25;96,70;160,170;208,220;255,250',  # ç»å…¸æ¸¯ç‰‡è‰²è°ƒ
            'æ¸¯é£æš—è°ƒ': '0,0;32,10;96,55;160,140;224,190;255,230',  # æ·±æ²‰æ¸¯é£
            'æ¸¯é£éœ“è™¹': '0,10;48,35;96,75;160,190;208,240;255,255',  # éœ“è™¹å¤œæ™¯
            
            # === ç¤¾äº¤åª’ä½“é£æ ¼ ===
            'å°çº¢ä¹?: '0,30;64,90;128,155;192,220;255,250',  # æ›´æ¸©æš–æ˜äº®ï¼Œå¼ºåŒ–å°çº¢ä¹¦ç‰¹è‰?
            'Instagram': '0,15;48,70;96,125;160,180;224,230;255,250',  # æ›´æ—¶å°šç°ä»£ï¼Œå¼ºåŒ–INSç‰¹è‰²
            'TikTokæµè¡Œ': '0,15;64,90;128,160;192,220;255,248',  # å¹´è½»æ´»åŠ›
            
            # === æ—¶å°šæ‘„å½± ===
            'æ—¶å°šæ‚å¿—': '0,0;48,30;96,75;160,185;208,235;255,255',  # æ—¶å°šå¤§ç‰‡
            'é«˜çº§ç?: '0,25;64,80;128,135;192,190;255,240',  # é«˜çº§ç°è°ƒ
            'è«å…°è¿ªè‰²': '0,40;64,95;128,150;192,205;255,235',  # è«å…°è¿ªè‰²è°?
            'å¥¶èŒ¶è‰?: '0,35;48,85;96,140;160,190;224,225;255,240',  # æ¸©æš–å¥¶èŒ¶è‰?
            
            # === è‰ºæœ¯é£æ ¼ ===
            'æ²¹ç”»è´¨æ„Ÿ': '0,10;48,60;96,115;160,170;224,220;255,245',  # æ²¹ç”»åšé‡æ„?
            'æ°´å½©ç”?: '0,40;64,105;128,170;192,220;255,245',  # æ°´å½©é€æ˜æ„?
            'ç´ æé£æ ¼': '0,0;64,45;128,105;192,165;255,220',  # ç´ æå¯¹æ¯”
            'ç‰ˆç”»æ•ˆæœ': '0,0;32,15;96,65;160,155;224,210;255,240',  # ç‰ˆç”»è´¨æ„Ÿ
            
            # === ç‰¹æ®Šæ•ˆæœï¼ˆæ•ˆæœå¼ºçƒˆï¼‰ ===
            'æ¢¦å¹»ç´«è°ƒ': '0,20;48,75;96,135;160,190;224,235;255,250',  # æ¢¦å¹»æ„?
            'é’æ˜¥æ´»åŠ›': '0,30;64,100;128,170;192,225;255,250',  # æ´»åŠ›å››å°„
            'å•†ä¸šæ‘„å½±': '0,5;48,55;96,105;160,185;224,240;255,255',  # å•†ä¸šè´¨æ„Ÿ
            'å©šçº±æ‘„å½±': '0,40;64,105;128,170;192,225;255,248',  # æ›´æµªæ¼«æ¢¦å¹»ï¼Œä¸å…¶ä»–åŒºåˆ?
            'è¡—æ‹é£æ ¼': '0,15;48,70;96,125;160,185;224,230;255,245',  # è¡—å¤´æ„?
            
            # === å­£èŠ‚ä¸»é¢˜ ===
            'æ˜¥æ—¥æš–é˜³': '0,30;64,95;128,165;192,220;255,245',  # æ›´æ¸©æš–ï¼Œä¸æ—¥ç³»æ£®ç³»åŒºåˆ?
            'å¤æ—¥æ¸…å‡‰': '0,20;48,80;96,140;160,200;224,240;255,250',  # å¤æ—¥æ¸…çˆ½
            'ç§‹æ—¥é‡‘é»„': '0,15;48,65;96,115;160,175;224,225;255,245',  # ç§‹æ—¥é‡‘è‰²
            'å†¬æ—¥é›ªæ™¯': '0,25;64,90;128,160;192,215;255,250',  # è°ƒæ•´ä¸ºæ›´å†·å³»ï¼Œä¸æ—¥ç³»æ¸…æ–°åŒºåˆ†
            
            # === æç«¯æ•ˆæœï¼ˆæµ‹è¯•ç”¨ï¼?===
            'æç«¯æäº®': '0,80;64,140;128,190;192,230;255,255',  # æç«¯æäº®æ•ˆæœ
            'æç«¯å‹æš—': '0,0;64,20;128,60;192,120;255,180',  # æç«¯å‹æš—æ•ˆæœ
            'åè½¬æ•ˆæœ': '0,255;64,192;128,128;192,64;255,0',  # åè½¬è‰²è°ƒ
            'Så‹å¢å¼?: '0,0;32,5;96,50;160,205;224,250;255,255',  # å¼ºçƒˆSå?
            
            # === äººåƒæ‘„å½± ===
            'äººåƒç¾é¢œ': '0,25;48,85;96,140;160,190;224,230;255,245',  # æŸ”å’Œç¾é¢œï¼Œä¸å…¶ä»–åŒºåˆ†
            'äººåƒè´¨æ„Ÿ': '0,10;48,60;96,110;160,175;224,225;255,250',  # è´¨æ„Ÿäººåƒ
            'äººåƒæŸ”å…‰': '0,35;64,100;128,165;192,215;255,240',  # æŸ”å…‰æ•ˆæœ
            
            # === é£æ™¯æ‘„å½± ===
            'é£æ™¯å¢å¼º': '0,5;48,55;96,110;160,180;224,235;255,255',  # é£æ™¯å¯¹æ¯”å¢å¼ºï¼Œä¸å•†ä¸šæ‘„å½±åŒºåˆ†
            'è‡ªç„¶é£å…‰': '0,15;64,85;128,150;192,205;255,245',  # è‡ªç„¶è‰²å½©
            'å±±æ°´ç”»æ„': '0,20;48,75;96,130;160,185;224,220;255,240',  # å±±æ°´æ„å¢ƒ
            
            # === ç”µå½±é£æ ¼ ===
            'ç”µå½±èƒ¶ç‰‡': '0,15;48,65;96,120;160,175;224,215;255,240',  # èƒ¶ç‰‡è´¨æ„Ÿï¼Œä¸ç§‹æ—¥é‡‘é»„åŒºåˆ†
            'ç”µå½±å†·è°ƒ': '0,0;48,30;96,80;160,160;224,210;255,245',  # å†·è‰²è°ƒç”µå½?
            'ç”µå½±æš–è°ƒ': '0,20;48,75;96,125;160,185;224,230;255,250',  # æš–è‰²è°ƒç”µå½?
            
            # === å¤å¤é£æ ¼ ===
            'å¤å¤èƒ¶ç‰‡': '0,10;48,55;96,105;160,165;224,205;255,235',  # å¤å¤èƒ¶ç‰‡ï¼Œä¸ç”µå½±èƒ¶ç‰‡åŒºåˆ†
            'å¤å¤æš–è°ƒ': '0,25;48,80;96,135;160,190;224,225;255,245',  # å¤å¤æš–è‰²ï¼Œä¸äººåƒç¾é¢œåŒºåˆ†
            'æ€€æ—§è‰²è°?: '0,5;48,50;96,100;160,160;224,200;255,230',  # æ€€æ—§æ„Ÿ
            
            # === ç°ä»£é£æ ¼ ===
            'ç°ä»£ç®€çº?: '0,20;64,85;128,145;192,200;255,245',  # ç®€çº¦ç°ä»£ï¼Œä¸æ—¥ç³»æ£®ç³»åŒºåˆ?
            'ç§‘æŠ€æ„?: '0,0;48,25;96,75;160,175;224,235;255,255',  # ç§‘æŠ€å†·å³»ï¼Œä¸æ¸¯é£ç»å…¸åŒºåˆ†
            'æœªæ¥ä¸»ä¹‰': '0,10;48,40;96,85;160,185;224,240;255,255',  # æœªæ¥æ„?
            
            # === å¯¹æ¯”åº¦ç³»åˆ?===
            'é«˜å¯¹æ¯”åº¦': '0,0;64,40;128,120;192,200;255,255',  # å¼ºçƒˆå¯¹æ¯”
            'è¶…é«˜å¯¹æ¯”': '0,0;48,20;128,128;208,235;255,255',  # æç«¯å¯¹æ¯”
            'æŸ”å’Œå¯¹æ¯”': '0,30;64,90;128,155;192,210;255,245',  # æŸ”å’Œå¯¹æ¯”ï¼Œä¸å°çº¢ä¹¦åŒºåˆ?
            'æš—è°ƒé£æ ¼': '0,0;64,35;128,90;192,150;255,200',  # æš—è°ƒå¤„ç†
            'äº®è°ƒé£æ ¼': '0,50;64,110;128,175;192,220;255,250',  # äº®è°ƒå¤„ç†
        }

    def get_preset_curve(self, preset_style, unique_id=None):
        try:
            # è·å–é¢„è®¾æ›²çº¿ç‚?
            preset_curves = self.get_preset_curves()
            curve_points = preset_curves.get(preset_style, '0,0;255,255')
            
            return (curve_points,)
            
        except Exception as e:
            print(f"CurvePresetNode error: {e}")
            return ('0,0;255,255',)

class PhotoshopHistogramNode:
    """PSç›´æ–¹å›¾åŠŸèƒ½èŠ‚ç‚?- æä¾›ç›´æ–¹å›¾åˆ†æå’Œè‰²é˜¶è°ƒæ•´"""
    
    @classmethod
    def INPUT_TYPES(cls):
        return {
            'required': {
                'image': ('IMAGE',),
                'channel': (['RGB', 'R', 'G', 'B', 'Luminance'], {'default': 'RGB'}),
            },
            'optional': {
                'input_black': ('FLOAT', {
                    'default': 0.0,
                    'min': 0.0,
                    'max': 254.0,
                    'step': 1.0,
                    'display': 'slider',
                    'tooltip': 'è¾“å…¥é»‘åœºç‚?(0-254)'
                }),
                'input_white': ('FLOAT', {
                    'default': 255.0,
                    'min': 1.0,
                    'max': 255.0,
                    'step': 1.0,
                    'display': 'slider',
                    'tooltip': 'è¾“å…¥ç™½åœºç‚?(1-255)'
                }),
                'gamma': ('FLOAT', {
                    'default': 1.0,
                    'min': 0.1,
                    'max': 9.99,
                    'step': 0.01,
                    'display': 'slider',
                    'tooltip': 'ä¼½é©¬å€?(0.1-9.99)'
                }),
                'output_black': ('FLOAT', {
                    'default': 0.0,
                    'min': 0.0,
                    'max': 254.0,
                    'step': 1.0,
                    'display': 'slider',
                    'tooltip': 'è¾“å‡ºé»‘åœºç‚?(0-254)'
                }),
                'output_white': ('FLOAT', {
                    'default': 255.0,
                    'min': 1.0,
                    'max': 255.0,
                    'step': 1.0,
                    'display': 'slider',
                    'tooltip': 'è¾“å‡ºç™½åœºç‚?(1-255)'
                }),
                'auto_levels': ('BOOLEAN', {
                    'default': False,
                    'tooltip': 'è‡ªåŠ¨è‰²é˜¶è°ƒæ•´'
                }),
                'auto_contrast': ('BOOLEAN', {
                    'default': False,
                    'tooltip': 'è‡ªåŠ¨å¯¹æ¯”åº¦è°ƒæ•?
                }),
                'clip_percentage': ('FLOAT', {
                    'default': 0.1,
                    'min': 0.0,
                    'max': 5.0,
                    'step': 0.1,
                    'display': 'slider',
                    'tooltip': 'è‡ªåŠ¨è°ƒæ•´æ—¶çš„è£å‰ªç™¾åˆ†æ¯?
                }),
            },
            'hidden': {'unique_id': 'UNIQUE_ID'}
        }
    
    RETURN_TYPES = ('IMAGE', 'IMAGE', 'STRING', 'STRING')
    RETURN_NAMES = ('image', 'histogram_image', 'histogram_data', 'statistics')
    FUNCTION = 'apply_histogram_adjustment'
    CATEGORY = 'Image/Analysis'
    OUTPUT_NODE = False
    
    @classmethod
    def IS_CHANGED(cls, image, channel, input_black=0.0, input_white=255.0, gamma=1.0, 
                   output_black=0.0, output_white=255.0, auto_levels=False, auto_contrast=False, 
                   clip_percentage=0.1, unique_id=None):
        return f"{channel}_{input_black}_{input_white}_{gamma}_{output_black}_{output_white}_{auto_levels}_{auto_contrast}_{clip_percentage}"

    def apply_histogram_adjustment(self, image, channel, input_black=0.0, input_white=255.0, gamma=1.0,
                                 output_black=0.0, output_white=255.0, auto_levels=False, auto_contrast=False,
                                 clip_percentage=0.1, unique_id=None):
        try:
            # ç¡®ä¿è¾“å…¥å›¾åƒæ ¼å¼æ­£ç¡®
            if image is None:
                raise ValueError("Input image is None")
            
            # å¤„ç†æ‰¹æ¬¡ç»´åº¦
            if image.dim() == 4:  # Batch dimension exists
                batch_size = image.shape[0]
                results = []
                histogram_images = []
                histogram_data_list = []
                statistics_list = []
                
                for b in range(batch_size):
                    result, hist_image, hist_data, stats = self._process_single_image(
                        image[b], channel, input_black, input_white, gamma,
                        output_black, output_white, auto_levels, auto_contrast, clip_percentage
                    )
                    results.append(result)
                    histogram_images.append(hist_image)
                    histogram_data_list.append(hist_data)
                    statistics_list.append(stats)
                
                # åˆå¹¶æ‰¹æ¬¡ç»“æœ
                combined_hist = "\n".join([f"Image {i+1}:\n{hist}" for i, hist in enumerate(histogram_data_list)])
                combined_stats = "\n".join([f"Image {i+1}:\n{stats}" for i, stats in enumerate(statistics_list)])
                
                return (torch.stack(results, dim=0), torch.stack(histogram_images, dim=0), combined_hist, combined_stats)
            else:
                result, hist_image, hist_data, stats = self._process_single_image(
                    image, channel, input_black, input_white, gamma,
                    output_black, output_white, auto_levels, auto_contrast, clip_percentage
                )
                return (result.unsqueeze(0), hist_image.unsqueeze(0), hist_data, stats)
                
        except Exception as e:
            print(f"PhotoshopHistogramNode error: {e}")
            # è¿”å›åŸå§‹å›¾åƒä½œä¸ºfallback
            fallback_hist = self._create_fallback_histogram_image()
            return (image, fallback_hist, "Error generating histogram", "Error calculating statistics")
    
    def _process_single_image(self, image, channel, input_black, input_white, gamma, output_black, output_white, auto_levels, auto_contrast, clip_percentage):
        # ç¡®ä¿å›¾åƒåœ¨æ­£ç¡®çš„è®¾å¤‡ä¸?
        device = get_torch_device()
        image = image.to(device)
        
        # å¤„ç†å›¾åƒç»´åº¦ (HWC)
        if image.dim() == 3:
            h, w, c = image.shape
        else:
            raise ValueError(f"Unexpected image dimensions: {image.shape}")
        
        # å°†å›¾åƒè½¬æ¢ä¸º0-255èŒƒå›´ç”¨äºç›´æ–¹å›¾åˆ†æ?
        img_255 = (image * 255.0).clamp(0, 255)
        
        # ç”Ÿæˆç›´æ–¹å›¾æ•°æ®å’Œå›¾åƒ
        histogram_data = self._generate_histogram_data(img_255, channel)
        histogram_image = self._generate_histogram_image(img_255, channel, input_black, input_white, gamma)
        
        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        statistics = self._calculate_statistics(img_255, channel)
        
        # åº”ç”¨è‡ªåŠ¨è°ƒæ•´ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if auto_levels or auto_contrast:
            input_black, input_white, gamma = self._calculate_auto_levels(
                img_255, channel, auto_levels, auto_contrast, clip_percentage
            )
        
        # åº”ç”¨è‰²é˜¶è°ƒæ•´
        result = self._apply_levels_adjustment(
            image, channel, input_black, input_white, gamma, output_black, output_white
        )
        
        return result, histogram_image, histogram_data, statistics
    
    def _generate_histogram_data(self, img_255, channel):
        """ç”Ÿæˆç›´æ–¹å›¾æ•°æ?""
        histogram_info = []
        
        if channel == 'RGB' or channel == 'Luminance':
            if channel == 'RGB':
                # RGBç»¼åˆç›´æ–¹å›?
                for c, color_name in enumerate(['Red', 'Green', 'Blue']):
                    if c < img_255.shape[2]:
                        channel_data = img_255[..., c].cpu().numpy().flatten()
                        hist, bins = np.histogram(channel_data, bins=256, range=(0, 255))
                        histogram_info.append(f"{color_name} Channel Histogram:")
                        histogram_info.append(f"  Bins: {len(hist)}")
                        histogram_info.append(f"  Peak: {np.argmax(hist)} (value: {np.max(hist)})")
                        histogram_info.append(f"  Mean: {np.mean(channel_data):.2f}")
                        histogram_info.append("")
            else:
                # äº®åº¦ç›´æ–¹å›?
                if img_255.shape[2] >= 3:
                    luminance = (img_255[..., 0] * 0.299 + 
                               img_255[..., 1] * 0.587 + 
                               img_255[..., 2] * 0.114)
                    lum_data = luminance.cpu().numpy().flatten()
                    hist, bins = np.histogram(lum_data, bins=256, range=(0, 255))
                    histogram_info.append("Luminance Histogram:")
                    histogram_info.append(f"  Bins: {len(hist)}")
                    histogram_info.append(f"  Peak: {np.argmax(hist)} (value: {np.max(hist)})")
                    histogram_info.append(f"  Mean: {np.mean(lum_data):.2f}")
        else:
            # å•é€šé“ç›´æ–¹å›?
            channel_idx = {'R': 0, 'G': 1, 'B': 2}.get(channel, 0)
            colors = {'R': 'red', 'G': 'green', 'B': 'blue'}
            color = colors.get(channel, 'white')
            
            if channel_idx < img_255.shape[2]:
                channel_data = img_255[..., channel_idx].cpu().numpy().flatten()
                hist, bins = np.histogram(channel_data, bins=256, range=(0, 255))
                
                # å½’ä¸€åŒ–ç›´æ–¹å›¾
                hist_normalized = (hist / np.max(hist)) * 255 if np.max(hist) > 0 else hist
                
                # ç»˜åˆ¶å•é€šé“ç›´æ–¹å›?
                histogram_info.append(f"{channel} Channel Histogram:")
                histogram_info.append(f"  Bins: {len(hist)}")
                histogram_info.append(f"  Peak: {np.argmax(hist)} (value: {np.max(hist)})")
                histogram_info.append(f"  Mean: {np.mean(channel_data):.2f}")
                histogram_info.append(f"  Std Dev: {np.std(channel_data):.2f}")
                
                # æ·»åŠ åˆ†å¸ƒä¿¡æ¯
                histogram_info.append(f"  Min: {np.min(channel_data):.2f}")
                histogram_info.append(f"  Max: {np.max(channel_data):.2f}")
                histogram_info.append(f"  Median: {np.median(channel_data):.2f}")
                
                # è®¡ç®—ç™¾åˆ†ä½æ•°
                p1, p99 = np.percentile(channel_data, [1, 99])
                histogram_info.append(f"  1st Percentile: {p1:.2f}")
                histogram_info.append(f"  99th Percentile: {p99:.2f}")
        
        return "\n".join(histogram_info)
    
    def _generate_histogram_image(self, img_255, channel, input_black=0, input_white=255, gamma=1.0):
        """ç”Ÿæˆç›´æ–¹å›¾å¯è§†åŒ–å›¾åƒ - ç»Ÿä¸€é£æ ¼çš„ç‰ˆæœ?""
        try:
            # è®¾ç½®å›¾åƒå¤§å°
            fig_width, fig_height = 6, 4
            fig, ax = plt.subplots(figsize=(fig_width, fig_height))
            
            # ç»Ÿä¸€é£æ ¼
            fig.patch.set_facecolor('#2a2a2a')  # å¤–éƒ¨èƒŒæ™¯
            ax.set_facecolor('#1a1a1a')  # å†…éƒ¨èƒŒæ™¯
            
            # è®¾ç½®ç½‘æ ¼çº¿å’Œè¾¹æ¡†
            gridColor = '#444444'
            ax.grid(True, color=gridColor, alpha=0.5, linestyle='-', linewidth=0.5)
            
            # è®¾ç½®è½´æ ‡ç­¾é¢œè‰?
            ax.tick_params(axis='x', colors='white', labelsize=8)
            ax.tick_params(axis='y', colors='white', labelsize=8)
            for spine in ax.spines.values():
                spine.set_color('#555555')
            
            # è®¾ç½®æ ‡é¢˜å’Œæ ‡ç­¾é¢œè‰?
            title_color = 'white'
            label_color = '#cccccc'
            
            if channel == 'RGB':
                # RGBç»¼åˆç›´æ–¹å›?- æ˜¾ç¤ºä¸‰ä¸ªé€šé“
                colors = ['#ff5555', '#55ff55', '#5555ff']  # æ›´é²œæ˜çš„RGBé¢œè‰²
                channel_names = ['Red', 'Green', 'Blue']
                
                for c, (color, name) in enumerate(zip(colors, channel_names)):
                    if c < img_255.shape[2]:
                        channel_data = img_255[..., c].cpu().numpy().flatten()
                        hist, bins = np.histogram(channel_data, bins=256, range=(0, 255))
                        
                        # ç»˜åˆ¶ç›´æ–¹å›?
                        ax.plot(bins[:-1], hist, color=color, alpha=0.8, linewidth=1.5, label=name)
                        ax.fill_between(bins[:-1], hist, alpha=0.3, color=color)
                
                ax.legend(loc='upper right', framealpha=0.7, facecolor='#2a2a2a', edgecolor='#555555', labelcolor='white')
                title = 'RGB Histogram'
                
            elif channel == 'Luminance':
                # äº®åº¦ç›´æ–¹å›?
                if img_255.shape[2] >= 3:
                    luminance = (img_255[..., 0] * 0.299 + 
                               img_255[..., 1] * 0.587 + 
                               img_255[..., 2] * 0.114)
                    lum_data = luminance.cpu().numpy().flatten()
                    hist, bins = np.histogram(lum_data, bins=256, range=(0, 255))
                    
                    ax.plot(bins[:-1], hist, color='#aaaaaa', linewidth=1.5)
                    ax.fill_between(bins[:-1], hist, alpha=0.5, color='#aaaaaa')
                    
                title = 'Luminance Histogram'
                
            else:
                # å•é€šé“ç›´æ–¹å›?
                channel_idx = {'R': 0, 'G': 1, 'B': 2}.get(channel, 0)
                colors = {'R': '#ff5555', 'G': '#55ff55', 'B': '#5555ff'}
                color = colors.get(channel, '#5555ff')
                
                if channel_idx < img_255.shape[2]:
                    channel_data = img_255[..., channel_idx].cpu().numpy().flatten()
                    hist, bins = np.histogram(channel_data, bins=256, range=(0, 255))
                    
                    ax.plot(bins[:-1], hist, color=color, linewidth=1.5)
                    ax.fill_between(bins[:-1], hist, alpha=0.5, color=color)
                    
                title = f'{channel} Channel Histogram'
            
            # æ·»åŠ è‰²é˜¶æŒ‡ç¤ºçº?
            if input_black > 0:
                ax.axvline(x=input_black, color='#ffffff', linestyle='--', alpha=0.7, linewidth=1, 
                          label=f'Black: {input_black:.0f}')
            if input_white < 255:
                ax.axvline(x=input_white, color='#ffffff', linestyle='--', alpha=0.7, linewidth=1, 
                          label=f'White: {input_white:.0f}')
            if gamma != 1.0:
                # æ˜¾ç¤ºä¼½é©¬ä¸­ç‚¹
                gamma_point = input_black + (input_white - input_black) * (0.5 ** (1/gamma))
                ax.axvline(x=gamma_point, color='#aaaaaa', linestyle=':', alpha=0.7, linewidth=1, 
                          label=f'Gamma: {gamma:.2f}')
            
            # è®¾ç½®æ ‡é¢˜å’Œæ ‡ç­?
            ax.set_title(title, fontsize=12, fontweight='bold', color=title_color, pad=10)
            ax.set_xlabel('Pixel Value (0-255)', fontsize=10, color=label_color)
            ax.set_ylabel('Frequency', fontsize=10, color=label_color)
            ax.set_xlim(0, 255)
            
            # å¦‚æœæœ‰è‰²é˜¶çº¿ï¼Œæ˜¾ç¤ºå›¾ä¾?
            if input_black > 0 or input_white < 255 or gamma != 1.0:
                ax.legend(loc='upper left', fontsize=8, framealpha=0.7, 
                         facecolor='#2a2a2a', edgecolor='#555555', labelcolor='white')
            
            # è°ƒæ•´å¸ƒå±€
            plt.tight_layout()
            
            # å°†å›¾åƒè½¬æ¢ä¸ºtensor
            buf = io.BytesIO()
            plt.savefig(buf, format='png', bbox_inches='tight', pad_inches=0.1, facecolor='#2a2a2a')
            plt.close(fig)
            
            # è½¬æ¢ä¸ºPILå›¾åƒ
            buf.seek(0)
            chart_pil = Image.open(buf)
            
            # è°ƒæ•´å›¾åƒå¤§å°
            chart_pil = chart_pil.resize((512, 512), Image.LANCZOS)
            
            # è½¬æ¢ä¸ºRGBæ¨¡å¼
            if chart_pil.mode != 'RGB':
                chart_pil = chart_pil.convert('RGB')
            
            # è½¬æ¢ä¸ºtensor
            chart_np = np.array(chart_pil) / 255.0
            chart_tensor = torch.from_numpy(chart_np).float().to(get_torch_device())
            
            return chart_tensor
        
        except Exception as e:
            print(f"Error generating histogram image: {e}")
            return self._create_fallback_histogram_image()
    
    def _create_fallback_histogram_image(self):
        """åˆ›å»ºå¤‡ç”¨ç›´æ–¹å›¾å›¾åƒ?- ç»Ÿä¸€é£æ ¼çš„ç‰ˆæœ?""
        try:
            # åˆ›å»ºä¸€ä¸ªç®€å•çš„é”™è¯¯å›¾åƒ
            fig, ax = plt.subplots(figsize=(5, 5), dpi=100)
            fig.patch.set_facecolor('#2a2a2a')  # å¤–éƒ¨èƒŒæ™¯
            
            ax.set_facecolor('#1a1a1a')  # å†…éƒ¨èƒŒæ™¯
            ax.text(0.5, 0.5, 'Error generating histogram\nPlease check console for details', 
                   horizontalalignment='center', verticalalignment='center',
                   transform=ax.transAxes, fontsize=12, color='#ff5555')
            ax.set_xlim(0, 255)
            ax.set_ylim(0, 255)
            ax.set_xlabel('Pixel Value', color='#cccccc', fontsize=10)
            ax.set_ylabel('Frequency', color='#cccccc', fontsize=10)
            ax.set_title('Histogram Error', color='white', fontsize=12)
            ax.tick_params(colors='#cccccc')
            
            # è®¾ç½®è¾¹æ¡†é¢œè‰²
            for spine in ax.spines.values():
                spine.set_color('#555555')
            
            # ç»˜åˆ¶ç½‘æ ¼çº?
            gridColor = '#444444'
            ax.grid(True, color=gridColor, alpha=0.5, linestyle='-', linewidth=0.5)
            
            # è½¬æ¢ä¸ºtensor
            buf = io.BytesIO()
            plt.savefig(buf, format='png', dpi=100, bbox_inches='tight', pad_inches=0.1, facecolor='#2a2a2a')
            plt.close(fig)
            buf.seek(0)
            
            pil_image = Image.open(buf)
            pil_image = pil_image.resize((512, 512), Image.LANCZOS)
            
            if pil_image.mode != 'RGB':
                pil_image = pil_image.convert('RGB')
            
            img_array = np.array(pil_image)
            histogram_tensor = torch.from_numpy(img_array).float() / 255.0
            
            return histogram_tensor.to(get_torch_device())
            
        except Exception as e:
            print(f"Error creating fallback histogram: {e}")
            # åˆ›å»ºä¸€ä¸ªçº¯è‰²å›¾åƒä½œä¸ºæœ€åçš„å¤‡ç”¨
            empty_chart = torch.ones((512, 512, 3), dtype=torch.float32).to(get_torch_device()) * 0.1
            # åœ¨ä¸­é—´ç»˜åˆ¶çº¢è‰²åå­—è¡¨ç¤ºé”™è¯?
            empty_chart[236:276, 236:276, 0] = 1.0
            empty_chart[236:276, 236:276, 1] = 0.0
            empty_chart[236:276, 236:276, 2] = 0.0
            return empty_chart

    def _calculate_statistics(self, img_255, channel):
        """è®¡ç®—å›¾åƒç»Ÿè®¡ä¿¡æ¯"""
        stats_info = []
        
        if channel == 'RGB':
            for c, color_name in enumerate(['Red', 'Green', 'Blue']):
                if c < img_255.shape[2]:
                    channel_data = img_255[..., c].cpu().numpy()
                    stats_info.append(f"{color_name} Channel Statistics:")
                    stats_info.append(f"  Mean: {np.mean(channel_data):.2f}")
                    stats_info.append(f"  Std Dev: {np.std(channel_data):.2f}")
                    stats_info.append(f"  Min: {np.min(channel_data):.2f}")
                    stats_info.append(f"  Max: {np.max(channel_data):.2f}")
                    stats_info.append("")
        elif channel == 'Luminance':
            if img_255.shape[2] >= 3:
                luminance = (img_255[..., 0] * 0.299 + 
                           img_255[..., 1] * 0.587 + 
                           img_255[..., 2] * 0.114)
                lum_data = luminance.cpu().numpy()
                stats_info.append("Luminance Statistics:")
                stats_info.append(f"  Mean: {np.mean(lum_data):.2f}")
                stats_info.append(f"  Std Dev: {np.std(lum_data):.2f}")
                stats_info.append(f"  Min: {np.min(lum_data):.2f}")
                stats_info.append(f"  Max: {np.max(lum_data):.2f}")
        else:
            channel_idx = {'R': 0, 'G': 1, 'B': 2}.get(channel, 0)
            if channel_idx < img_255.shape[2]:
                channel_data = img_255[..., channel_idx].cpu().numpy()
                stats_info.append(f"{channel} Channel Statistics:")
                stats_info.append(f"  Mean: {np.mean(channel_data):.2f}")
                stats_info.append(f"  Std Dev: {np.std(channel_data):.2f}")
                stats_info.append(f"  Min: {np.min(channel_data):.2f}")
                stats_info.append(f"  Max: {np.max(channel_data):.2f}")
                stats_info.append(f"  Median: {np.median(channel_data):.2f}")
                
                # æ·»åŠ å¯¹æ¯”åº¦å’Œäº®åº¦ä¿¡æ¯
                contrast = np.std(channel_data)
                brightness = np.mean(channel_data)
                stats_info.append(f"  Contrast (Std): {contrast:.2f}")
                stats_info.append(f"  Brightness (Mean): {brightness:.2f}")
                
                # åŠ¨æ€èŒƒå›?
                dynamic_range = np.max(channel_data) - np.min(channel_data)
                stats_info.append(f"  Dynamic Range: {dynamic_range:.2f}")
        
        return "\n".join(stats_info)
    
    def _calculate_auto_levels(self, img_255, channel, auto_levels, auto_contrast, clip_percentage):
        """è®¡ç®—è‡ªåŠ¨è‰²é˜¶å‚æ•°"""
        if channel == 'RGB':
            # å¯¹æ‰€æœ‰é€šé“è®¡ç®—
            all_data = img_255.cpu().numpy().flatten()
        elif channel == 'Luminance':
            if img_255.shape[2] >= 3:
                luminance = (img_255[..., 0] * 0.299 + 
                           img_255[..., 1] * 0.587 + 
                           img_255[..., 2] * 0.114)
                all_data = luminance.cpu().numpy().flatten()
            else:
                all_data = img_255[..., 0].cpu().numpy().flatten()
        else:
            channel_idx = {'R': 0, 'G': 1, 'B': 2}.get(channel, 0)
            if channel_idx < img_255.shape[2]:
                all_data = img_255[..., channel_idx].cpu().numpy().flatten()
            else:
                all_data = img_255[..., 0].cpu().numpy().flatten()
        
        # è®¡ç®—ç™¾åˆ†ä½æ•°æ¥ç¡®å®šé»‘ç™½åœºç‚?
        low_percentile = clip_percentage
        high_percentile = 100 - clip_percentage
        
        input_black = np.percentile(all_data, low_percentile)
        input_white = np.percentile(all_data, high_percentile)
        
        # ç¡®ä¿æœ‰æ•ˆèŒƒå›´
        input_black = max(0, min(254, input_black))
        input_white = max(input_black + 1, min(255, input_white))
        
        # ä¼½é©¬å€¼ä¿æŒ?.0ï¼ˆé™¤ééœ€è¦ç‰¹æ®Šè°ƒæ•´ï¼‰
        gamma = 1.0
        
        # å¦‚æœåªæ˜¯è‡ªåŠ¨å¯¹æ¯”åº¦ï¼Œè°ƒæ•´ä¼½é©¬å€?
        if auto_contrast and not auto_levels:
            # è®¡ç®—ä¸­é—´è°ƒçš„ä½ç½®æ¥è°ƒæ•´ä¼½é©?
            median_val = np.median(all_data)
            if input_white > input_black:
                normalized_median = (median_val - input_black) / (input_white - input_black)
                if normalized_median > 0 and normalized_median < 1:
                    # è°ƒæ•´ä¼½é©¬ä½¿ä¸­é—´è°ƒæ›´æ¥è¿?.5
                    gamma = np.log(0.5) / np.log(normalized_median)
                    gamma = max(0.1, min(9.99, gamma))
        
        return input_black, input_white, gamma
    
    def _apply_levels_adjustment(self, image, channel, input_black, input_white, gamma, output_black, output_white):
        """åº”ç”¨è‰²é˜¶è°ƒæ•´"""
        device = image.device
        
        # å°†å›¾åƒè½¬æ¢ä¸º0-255èŒƒå›´
        img_255 = (image * 255.0).clamp(0, 255)
        
        # ç¡®ä¿å‚æ•°æœ‰æ•ˆ
        input_black = max(0, min(254, input_black))
        input_white = max(input_black + 1, min(255, input_white))
        output_black = max(0, min(254, output_black))
        output_white = max(output_black + 1, min(255, output_white))
        gamma = max(0.1, min(9.99, gamma))
        
        # åº”ç”¨è‰²é˜¶è°ƒæ•´
        if channel == 'RGB':
            # å¯¹æ‰€æœ‰é€šé“åº”ç”¨
            result = torch.zeros_like(img_255)
            for c in range(min(3, img_255.shape[2])):
                result[..., c] = self._apply_levels_to_channel(
                    img_255[..., c], input_black, input_white, gamma, output_black, output_white
                )
            # å¦‚æœæœ‰alphaé€šé“ï¼Œä¿æŒä¸å?
            if img_255.shape[2] > 3:
                result[..., 3:] = img_255[..., 3:]
        elif channel == 'Luminance':
            # å¯¹äº®åº¦åº”ç”¨è°ƒæ•´ï¼Œä¿æŒè‰²å½©
            if img_255.shape[2] >= 3:
                # è½¬æ¢åˆ°HSVç©ºé—´
                result = self._adjust_luminance_only(img_255, input_black, input_white, gamma, output_black, output_white)
            else:
                result = self._apply_levels_to_channel(
                    img_255[..., 0], input_black, input_white, gamma, output_black, output_white
                ).unsqueeze(-1)
        else:
            # å¯¹å•ä¸ªé€šé“åº”ç”¨
            channel_idx = {'R': 0, 'G': 1, 'B': 2}.get(channel, 0)
            result = img_255.clone()
            if channel_idx < img_255.shape[2]:
                result[..., channel_idx] = self._apply_levels_to_channel(
                    img_255[..., channel_idx], input_black, input_white, gamma, output_black, output_white
                )
        
        # è½¬æ¢å›?-1èŒƒå›´
        result = (result / 255.0).clamp(0, 1)
        
        return result
    
    def _apply_levels_to_channel(self, channel_data, input_black, input_white, gamma, output_black, output_white):
        """å¯¹å•ä¸ªé€šé“åº”ç”¨è‰²é˜¶è°ƒæ•´"""
        # è¾“å…¥èŒƒå›´è°ƒæ•´
        normalized = (channel_data - input_black) / (input_white - input_black)
        normalized = torch.clamp(normalized, 0, 1)
        
        # ä¼½é©¬æ ¡æ­£
        gamma_corrected = torch.pow(normalized, 1.0 / gamma)
        
        # è¾“å‡ºèŒƒå›´è°ƒæ•´
        result = gamma_corrected * (output_white - output_black) + output_black
        
        return torch.clamp(result, 0, 255)
    
    def _adjust_luminance_only(self, img_255, input_black, input_white, gamma, output_black, output_white):
        """ä»…è°ƒæ•´äº®åº¦ï¼Œä¿æŒè‰²å½©"""
        # è½¬æ¢åˆ°HSVç©ºé—´è¿›è¡Œäº®åº¦è°ƒæ•´
        rgb = img_255 / 255.0
        
        # ç®€åŒ–çš„RGBåˆ°HSVè½¬æ¢ï¼ˆä»…å¤„ç†Vé€šé“ï¼?
        max_vals, _ = torch.max(rgb, dim=2, keepdim=True)
        min_vals, _ = torch.min(rgb, dim=2, keepdim=True)
        
        # è°ƒæ•´Vé€šé“ï¼ˆäº®åº¦ï¼‰
        v_channel = max_vals.squeeze(-1) * 255.0
        adjusted_v = self._apply_levels_to_channel(v_channel, input_black, input_white, gamma, output_black, output_white)
        adjusted_v = adjusted_v / 255.0
        
        # è®¡ç®—è°ƒæ•´æ¯”ä¾‹
        adjustment_ratio = torch.where(max_vals.squeeze(-1) > 0, adjusted_v / max_vals.squeeze(-1), torch.ones_like(adjusted_v))
        adjustment_ratio = adjustment_ratio.unsqueeze(-1)
        
        # åº”ç”¨è°ƒæ•´æ¯”ä¾‹åˆ°RGB
        result = rgb * adjustment_ratio
        result = torch.clamp(result, 0, 1) * 255.0
        
        return result

# å¯¼å‡ºèŠ‚ç‚¹æ˜ å°„
NODE_CLASS_MAPPINGS = {
    "PhotoshopCurveNode": PhotoshopCurveNode,
    "PhotoshopHistogramNode": PhotoshopHistogramNode,
    "CurvePresetNode": CurvePresetNode,
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "PhotoshopCurveNode": "ğŸ¨ PS Curve (Professional)",
    "PhotoshopHistogramNode": "ğŸ“Š PS Histogram & Levels",
    "CurvePresetNode": "ğŸ¨ PS Curve Preset",
}

# Webç›®å½•è®¾ç½®
WEB_DIRECTORY = "./web"
